{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/myenv/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "from sklearn import tree\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import PredefinedSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn import model_selection\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import metrics \n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import operator\n",
    "import graphviz  \n",
    "import pydotplus\n",
    "from IPython.display import Image  \n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "raw_data = pd.read_csv(\"bank-additional-full.csv\",delimiter = \";\")\n",
    "raw_data = raw_data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'no': 36548, 'yes': 4640})\n",
      "(0.09744495076204493, 'duration')\n",
      "(0.07758409907879295, 'euribor3m')\n",
      "(0.0681771292828563, 'cons.price.idx')\n",
      "(0.06817712928285628, 'cons.conf.idx')\n",
      "(0.06222040677351051, 'nr.employed')\n",
      "(0.054568132557260715, 'emp.var.rate')\n",
      "(0.03154246805520029, 'pdays')\n",
      "(0.030383612679616152, 'poutcome')\n",
      "(0.026406581004977794, 'month')\n",
      "(0.019268877762732103, 'previous')\n",
      "(0.014120642590666126, 'age')\n",
      "(0.011645721145540237, 'contact')\n",
      "(0.009858724326144045, 'job')\n",
      "(0.00577430676511924, 'default')\n",
      "(0.003334438122576158, 'campaign')\n",
      "(0.0023896903228810638, 'education')\n",
      "(0.0014338512748518547, 'marital')\n",
      "(0.00032199848153421917, 'day_of_week')\n",
      "(6.90830137016589e-05, 'housing')\n",
      "(1.3380897777300754e-05, 'loan')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "job            y  \n",
       "admin.         no     9070\n",
       "               yes    1352\n",
       "blue-collar    no     8616\n",
       "               yes     638\n",
       "entrepreneur   no     1332\n",
       "               yes     124\n",
       "housemaid      no      954\n",
       "               yes     106\n",
       "management     no     2596\n",
       "               yes     328\n",
       "retired        no     1286\n",
       "               yes     434\n",
       "self-employed  no     1272\n",
       "               yes     149\n",
       "services       no     3646\n",
       "               yes     323\n",
       "student        no      600\n",
       "               yes     275\n",
       "technician     no     6013\n",
       "               yes     730\n",
       "unemployed     no      870\n",
       "               yes     144\n",
       "unknown        no      293\n",
       "               yes      37\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#******************data preprocessing*********************\n",
    "#mutual information\n",
    "raw_array_n = raw_data.as_matrix()\n",
    "x_n = raw_array_n[:,0:-1]\n",
    "y_n = raw_array_n[:,-1]\n",
    "print(Counter(raw_data['y']))\n",
    "scores = []\n",
    "for i in range(x_n.shape[1]):\n",
    "    scores.append((metrics.mutual_info_score(x_n[:,i], y_n), raw_data.columns[i]))\n",
    "           \n",
    "for score in sorted(scores,reverse=True):\n",
    "    print(score)\n",
    "    \n",
    "#check missing values ('unknown' )\n",
    "raw_data.loc[:,['job', 'y']].groupby(['job','y']).size() #also check marital, education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# deal with missing values and remove features\n",
    "raw_data = raw_data[raw_data['job'] != 'unknown']\n",
    "raw_data = raw_data[raw_data['marital']!= 'unknown']\n",
    "del raw_data['default']\n",
    "del raw_data['duration']\n",
    "del raw_data['loan']\n",
    "del raw_data['housing']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding\n",
    "\n",
    "#transform to labelencoder\n",
    "for column in raw_data.columns:\n",
    "    if raw_data[column].dtype == type(object):\n",
    "        le = LabelEncoder()\n",
    "        raw_data[column] = le.fit_transform(raw_data[column])\n",
    "        \n",
    "#transform to onehotencode\n",
    "for column in [ 'poutcome', 'contact','education','marital','job','month', 'day_of_week']:\n",
    "    ohe = pd.get_dummies(raw_data[column], prefix = column)\n",
    "    raw_data = raw_data.drop(column, 1).join(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new dataset shape: (40787, 52)\n"
     ]
    }
   ],
   "source": [
    "#new dataset\n",
    "raw_data = raw_data.drop('y',1).join(raw_data['y'])\n",
    "raw_array = raw_data.as_matrix()\n",
    "print(\"new dataset shape:\", raw_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 36193, 1: 4594})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unbalanced data\n",
    "Counter(raw_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#************** split dataset******************\n",
    "raw_array = raw_data.as_matrix()\n",
    "raw_x = raw_array[:,0:-1]\n",
    "raw_y = raw_array[:,-1]\n",
    "x_train_val, x_test, y_train_val, y_test = train_test_split(raw_x, raw_y, test_size=0.1, random_state=0)\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_val,y_train_val, test_size = 2.0/7.0, random_state = 0)\n",
    "x_train, y_train = SMOTE().fit_sample(x_train, y_train) #resample training data ADASYN SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the random classifier:\n",
      "0.1756919374247894\n",
      "Recall of the random classifier:\n",
      "0.4910313901345291\n"
     ]
    }
   ],
   "source": [
    "#random baseline\n",
    "y_random = np.random.randint(2, size = y_test.shape[0])\n",
    "print(\"F1 score of the random classifier:\")\n",
    "print(metrics.f1_score(y_test, y_random,labels = 1))\n",
    "print(\"Recall of the random classifier:\")\n",
    "print(metrics.recall_score(y_test, y_random, labels = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of default decision tree on training set:\n",
      "0.9940456858287323\n",
      "The recall of default decision tree on training set:\n",
      "0.9889707466287536\n",
      "The f1 score of default decision tree on validation set:\n",
      "0.31979695431472077\n",
      "The recall of default decision tree on validation set:\n",
      "0.33187006145741876\n"
     ]
    }
   ],
   "source": [
    "#single decision tree\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "dt = dt.fit(x_train, y_train)\n",
    "y_pred_dt_train = dt.predict(x_train)\n",
    "y_pred_dt_val = dt.predict(x_val)\n",
    "print(\"The f1 score of default decision tree on training set:\")\n",
    "print(metrics.f1_score(y_train, y_pred_dt_train, labels =1))\n",
    "print(\"The recall of default decision tree on training set:\")\n",
    "print(metrics.recall_score(y_train, y_pred_dt_train, labels=1))\n",
    "print(\"The f1 score of default decision tree on validation set:\")\n",
    "print(metrics.f1_score(y_val, y_pred_dt_val, labels = 1))\n",
    "print(\"The recall of default decision tree on validation set:\")\n",
    "print(metrics.recall_score(y_val, y_pred_dt_val, labels=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of simple LRG on training set:\n",
      "0.7126271003100887\n",
      "The recall of simple LRG on training set:\n",
      "0.638619620007755\n",
      "The f1 score of simple LRG on validation set:\n",
      "0.42671501964339675\n",
      "The recall of simple LRG on validation set:\n",
      "0.6198419666374012\n"
     ]
    }
   ],
   "source": [
    "#single logistic regression\n",
    "lgr = LogisticRegression()\n",
    "lgr = lgr.fit(x_train, y_train)\n",
    "y_pred_lgr_train = lgr.predict(x_train)\n",
    "y_pred_lgr_val = lgr.predict(x_val)\n",
    "print(\"The f1 score of simple LRG on training set:\")\n",
    "print(metrics.f1_score(y_train, y_pred_lgr_train, labels = 1))\n",
    "print(\"The recall of simple LRG on training set:\")\n",
    "print(metrics.recall_score(y_train, y_pred_lgr_train, labels=1))\n",
    "print(\"The f1 score of simple LRG on validation set:\")\n",
    "print(metrics.f1_score(y_val, y_pred_lgr_val, labels = 1))\n",
    "print(\"The recall of simple LRG on validation set:\")\n",
    "print(metrics.recall_score(y_val, y_pred_lgr_val, labels=1) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of simple SVM on training set:\n",
      "0.7447292220068442\n",
      "The recall of simple SVM on training set:\n",
      "0.6703718064710698\n",
      "The f1 score of simple SVM on validation set:\n",
      "0.448742746615087\n",
      "The recall of simple SVM on validation set:\n",
      "0.611062335381914\n"
     ]
    }
   ],
   "source": [
    "# svm\n",
    "svm = SVC()\n",
    "svm = svm.fit(x_train, y_train)\n",
    "y_pred_svm_train = svm.predict(x_train)\n",
    "y_pred_svm_val = svm.predict(x_val)\n",
    "print(\"The f1 score of simple SVM on training set:\")\n",
    "print(metrics.f1_score(y_train, y_pred_svm_train,labels = 1))\n",
    "print(\"The recall of simple SVM on training set:\")\n",
    "print(metrics.recall_score(y_train, y_pred_svm_train, labels=1))\n",
    "print(\"The f1 score of simple SVM on validation set:\")\n",
    "print(metrics.f1_score(y_val, y_pred_svm_val,labels = 1))\n",
    "print(\"The recall of simple SVM on validation set:\")\n",
    "print(metrics.recall_score(y_val, y_pred_svm_val, labels=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *****************Grid search*****************\n",
    "\n",
    "from sklearn.metrics import make_scorer, f1_score, recall_score\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=7)\n",
    "\n",
    "x_new = np.concatenate((x_train,x_val ),axis=0)\n",
    "y_new = np.concatenate((y_train,y_val ),axis=0)\n",
    "test_fold = np.zeros(x_new.shape[0])   \n",
    "test_fold[:x_train.shape[0]] = -1 #set the index of training set \n",
    "ps = PredefinedSplit(test_fold=test_fold)\n",
    "\n",
    "\n",
    "def grid(param_grid, ps, classifier, xdata = x_new, ydata = y_new):\n",
    "    #define a function to do grid search on different models\n",
    "    score = make_scorer(recall_score, pos_label=1) # define scorer, set positive lable = 1, or python will give out average recall\n",
    "    print(\"Tuning hyper-parameters\" )\n",
    "    clf = GridSearchCV(classifier, param_grid, cv= ps,\n",
    "                       scoring= score)\n",
    "    clf.fit(xdata, ydata)\n",
    "    print(\"Best parameters set found:\")\n",
    "    print(clf.best_params_)\n",
    "    print(\"Best recall:\")\n",
    "    print(clf.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On logistic regression model:\n",
      "Tuning hyper-parameters\n",
      "Best parameters set found:\n",
      "{'C': 0.1, 'tol': 0.01}\n",
      "Best recall:\n",
      "0.7216856892010536\n"
     ]
    }
   ],
   "source": [
    "# tune logistic regression parameters\n",
    "param_grid = {'C': [ 0.1, 1, 10, 100],'tol': [1e-6, 1e-5, 1e-4, 1e-3, 1e-2]}\n",
    "classifier = LogisticRegression()\n",
    "print(\"On logistic regression model:\")\n",
    "grid(param_grid, ps, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36076366030283086\n"
     ]
    }
   ],
   "source": [
    "# f1 on validation data\n",
    "tuned_lgr = LogisticRegression(C = 0.1, tol = 0.01)\n",
    "tuned_lgr = tuned_lgr.fit(x_train, y_train)\n",
    "y_tuned_lgr_val = tuned_lgr.predict(x_val)\n",
    "print(metrics.f1_score(y_val, y_tuned_lgr_val, labels = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On decision tree model:\n",
      "Tuning hyper-parameters\n",
      "Best parameters set found:\n",
      "{'max_depth': 3, 'min_samples_split': 10}\n",
      "Best recall:\n",
      "0.568920105355575\n"
     ]
    }
   ],
   "source": [
    "# tune decision tree parameters\n",
    "param_grid = {'min_samples_split': range(10,200,20),'max_depth': range(1,40,2)} \n",
    "classifier = tree.DecisionTreeClassifier()\n",
    "print(\"On decision tree model:\")\n",
    "grid(param_grid, ps, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4421699078812692\n"
     ]
    }
   ],
   "source": [
    "# f1 score on validation data\n",
    "tuned_dt = tree.DecisionTreeClassifier(max_depth= 3, min_samples_split= 10)\n",
    "tuned_dt = tuned_dt.fit(x_train, y_train)\n",
    "y_tuned_dt_val = tuned_dt.predict(x_val)\n",
    "print(metrics.f1_score(y_val, y_tuned_dt_val, labels = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plot the tree\n",
    "dot_simpletree = tree.export_graphviz(tuned_dt,out_file=None,feature_names=raw_data.columns[0:-1],class_names=np.array(['0', '1']) ,filled=True, rounded=True,special_characters=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_simpletree)  \n",
    "img = Image(graph.create_png())  \n",
    "graph.write_png(\"tuned_decisiontree.png\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On svm model:\n",
      "Tuning hyper-parameters\n",
      "Best parameters set found:\n",
      "{'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "Best recall:\n",
      "0.7067603160667252\n"
     ]
    }
   ],
   "source": [
    "#tune svm parameters\n",
    "param_grid = [\n",
    "  {'C': [1, 10, 100, 100], 'kernel': ['linear']},\n",
    "  {'C': [1, 10, 100, 100], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']}\n",
    " ]\n",
    "classifier = SVC()  \n",
    "print(\"On svm model:\")\n",
    "grid(param_grid, ps, classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of SVM on validation set:\n",
      "0.37251272559000465\n"
     ]
    }
   ],
   "source": [
    "#f1 score on validation data\n",
    "svm_tuned = SVC(C= 1, gamma = 0.0001, kernel = 'rbf')\n",
    "svm_tuned = svm_tuned.fit(x_train, y_train)\n",
    "y_tuned_svm_val = svm_tuned.predict(x_val)\n",
    "print(\"The f1 score of SVM on validation set:\")\n",
    "print(metrics.f1_score(y_val, y_tuned_svm_val,labels = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of gradient decision stump on validation set:\n",
      "0.35681768913938866\n",
      "The recall of gradient decision stump on validation set:\n",
      "0.7225636523266022\n"
     ]
    }
   ],
   "source": [
    "#*****************Gradient Boost*****************\n",
    "\n",
    "seed = 7\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01,max_depth=1, random_state=seed).fit(x_train, y_train)\n",
    "print(\"F1 score of gradient decision stump on validation set:\")\n",
    "print(metrics.f1_score(y_val, clf.predict(x_val), labels=1) )\n",
    "print(\"The recall of gradient decision stump on validation set:\")\n",
    "print(metrics.recall_score(y_val, clf.predict(x_val), labels=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of final decision tree on test set:\n",
      "0.5717488789237668\n",
      "F1 score of final  decision tree on test set:\n",
      "0.45333333333333337\n"
     ]
    }
   ],
   "source": [
    "#***************model on test data***************\n",
    "# decision tree\n",
    "clf_dt = tree.DecisionTreeClassifier(max_depth = 3, min_samples_split = 10)\n",
    "clf_dt = clf_dt.fit(x_train,y_train)\n",
    "print(\"Recall of final decision tree on test set:\")\n",
    "print(metrics.recall_score(y_test, clf_dt.predict(x_test), labels = 1))\n",
    "print(\"F1 score of final  decision tree on test set:\")\n",
    "print(metrics.f1_score(y_test, clf_dt.predict(x_test), labels = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall of final LGR on test set:\n",
      "0.7017937219730942\n",
      "F1 score of final  LGR on test set:\n",
      "0.3641652123327516\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression\n",
    "clf_lg = LogisticRegression(C = 0.1, tol = 0.01)\n",
    "clf_lg = clf_lg.fit(x_train, y_train)\n",
    "print(\"Recall of final LGR on test set:\")\n",
    "print(metrics.recall_score(y_test, clf_lg.predict(x_test), labels = 1))\n",
    "print(\"F1 score of final  LGR on test set:\")\n",
    "print(metrics.f1_score(y_test, clf_lg.predict(x_test), labels = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The f1 score of simple SVM on training set:\n",
      "0.3741620962827544\n",
      "The recall of simple SVM on training set:\n",
      "0.6883408071748879\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "clf_svm = SVC(C= 1, gamma = 0.0001, kernel = 'rbf')\n",
    "clf_svm = svm_tuned.fit(x_train, y_train)\n",
    "\n",
    "print(\"The f1 score of simple SVM on training set:\")\n",
    "print(metrics.f1_score(y_test, clf_svm.predict(x_test),labels = 1))\n",
    "print(\"The recall of simple SVM on training set:\")\n",
    "print(metrics.recall_score(y_test, clf_svm.predict(x_test), labels=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of gradient decision stump on validation set:\n",
      "0.3627960716348931\n",
      "The recall of gradient decision stump on validation set:\n",
      "0.7040358744394619\n"
     ]
    }
   ],
   "source": [
    "#Gradient boosting\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.01,max_depth=1, random_state=seed).fit(x_train, y_train)\n",
    "print(\"F1 score of gradient decision stump on validation set:\")\n",
    "print(metrics.f1_score(y_test, clf.predict(x_test), labels=1) )\n",
    "print(\"The recall of gradient decision stump on validation set:\")\n",
    "print(metrics.recall_score(y_test, clf.predict(x_test), labels=1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rank coefficient\n",
    "attribute_list = clf_lg.coef_.tolist()\n",
    "coe = attribute_list[0]\n",
    "coe=map(abs, coe)\n",
    "names = raw_data.columns\n",
    "coe, names = zip(*sorted(zip(coe, names), reverse = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.200306343371889 euribor3m\n",
      "0.19149877511898472 cons.price.idx\n",
      "0.18031514271927962 emp.var.rate\n",
      "0.11842276852759719 month_6\n",
      "0.08177252073368553 contact_0\n",
      "0.07965714657408533 contact_1\n",
      "0.04534372446904961 education_6\n",
      "0.04487848363124248 month_3\n",
      "0.04483701869990658 campaign\n",
      "0.03662543535996889 poutcome_0\n",
      "0.03459845657649612 poutcome_1\n",
      "0.032370555241437414 previous\n",
      "0.029644037004199417 marital_2\n",
      "0.02847054337201246 job_0\n",
      "0.0273306470232855 job_1\n",
      "0.02500676375531232 month_5\n",
      "0.022736101101847473 day_of_week_1\n",
      "0.020508215056443214 job_5\n",
      "0.020260203262017093 cons.conf.idx\n",
      "0.019994050834914782 education_2\n",
      "0.018391779665150907 day_of_week_4\n",
      "0.017873403259241947 job_8\n",
      "0.016860618145055472 month_0\n",
      "0.01672246954747583 month_4\n",
      "0.01597850401410519 job_7\n",
      "0.015617429031767884 marital_1\n",
      "0.014965429514085834 month_8\n",
      "0.014822782005787865 month_7\n",
      "0.01382781064540861 day_of_week_0\n",
      "0.01285896077448802 day_of_week_2\n",
      "0.011911233812830473 marital_0\n",
      "0.010427122957867376 education_0\n",
      "0.008464977318560647 education_5\n",
      "0.00828431393309302 education_3\n",
      "0.0074285454672211 day_of_week_3\n",
      "0.006753929170141321 month_1\n",
      "0.006390572877912793 month_9\n",
      "0.005401539278601874 job_2\n",
      "0.005203295800415037 job_4\n",
      "0.004583537800796078 job_3\n",
      "0.004142352943075007 poutcome_2\n",
      "0.004065461545149875 job_6\n",
      "0.003782658051763156 month_2\n",
      "0.003342277261579016 age\n",
      "0.0029304993919642888 nr.employed\n",
      "0.0028323911604463876 job_9\n",
      "0.002383851503949523 education_7\n",
      "0.0017099245304098456 pdays\n",
      "0.0012428698575876825 education_1\n",
      "0.000658589094703942 job_10\n",
      "0.00031539337345226615 education_4\n"
     ]
    }
   ],
   "source": [
    "for i, j in zip(coe, names):\n",
    "    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *************** fail to improve by bagging**************\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=5, random_state=seed)\n",
    "\n",
    "# #predict on bagging decision tree\n",
    "# score = make_scorer(recall_score, pos_label=1)\n",
    "# dt_bagging = BaggingClassifier(\n",
    "#     base_estimator=tree.DecisionTreeClassifier(), \n",
    "#     n_estimators=30, random_state=seed)\n",
    "# dt_bagging = dt_bagging.fit(x_train, y_train)\n",
    "# kfold_result_dt = model_selection.cross_val_score(\n",
    "#     dt_bagging, x_train_val, y_train_val, cv=ps, scoring=score)\n",
    "# print(\"The f1 score of bagging tuned decision tree on cross validation set:\")\n",
    "# print(\"the average f1-score is: \", kfold_result_dt.mean())\n",
    "# # print(\"The f1 score of bagging tuned decision tree on validation set is:\")\n",
    "# # print(metrics.f1_score(y_val, lgr.predict(x_val),average = 'micro'))\n",
    "\n",
    "\n",
    "# #predict on bagging svm\n",
    "# svm_bagging = BaggingClassifier(\n",
    "#     base_estimator=BaggingClassifier(base_estimator=SVC(), \n",
    "#                                      n_estimators=30, random_state=seed))\n",
    "# # svm_bagging = svm_bagging.fit(x_train,y_train)\n",
    "# # print(\"The f1 score of bagging tuned svm on training set:\")\n",
    "# # print(metrics.f1_score(y_train, svm_bagging.predict(x_train), average = 'micro'))\n",
    "\n",
    "# kfold_result_svm = model_selection.cross_val_score(\n",
    "#     svm_bagging, x_train_val, y_train_val, cv=kfold, scoring=\"f1_micro\")\n",
    "# print(\"The f1 score of bagging tuned svm on cross validation set:\")\n",
    "# print(\"the average f1-score is: \", kfold_result_svm.mean())\n",
    "\n",
    "# #predict on bagging logistic regression\n",
    "# lgr_bagging = BaggingClassifier(\n",
    "#     base_estimator=BaggingClassifier(base_estimator=LogisticRegression(), \n",
    "#                                      n_estimators=30, random_state=seed))\n",
    "# # lgr_bagging = lgr_bagging.fit(x_train,y_train)\n",
    "# # print(\"The f1 score of bagging tuned svm on training set:\")\n",
    "# # print(metrics.f1_score(y_train, lgr_bagging.predict(x_train), average = 'micro'))\n",
    "\n",
    "# kfold_result_lgr = model_selection.cross_val_score(\n",
    "#     lgr_bagging, x_train_val, y_train_val, cv=kfold, scoring=\"f1_micro\")\n",
    "# print(\"The f1 score of bagging tuned lrg on cross validation set:\")\n",
    "# print(\"the average f1-score is: \", kfold_result_lgr.mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
